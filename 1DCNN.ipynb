{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "1DCNN",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rameshkn/sharing-github/blob/master/1DCNN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bFL-LQ-fkUsN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from __future__ import absolute_import\n",
        "from __future__ import division\n",
        "from __future__ import print_function\n",
        "\n",
        "# Imports\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "\n",
        "from Data import fetch_1d_data\n",
        "from random import shuffle\n",
        "\n",
        "batch_size = 65536\n",
        "epochs = 28\n",
        "\n",
        "\n",
        "with tf.device(\"/gpu:0\"):\n",
        "    mean_conv1 = 0.5\n",
        "    mean_conv2 = 0.4\n",
        "    mean_conv3 = 0.35\n",
        "    mean_conv4 = 0.3\n",
        "\n",
        "    sd_conv1 = 0.45\n",
        "    sd_conv2 = 0.35\n",
        "    sd_conv3 = 0.25\n",
        "    sd_conv4 = 0.20\n",
        "\n",
        "    mode = tf.placeholder(dtype=tf.bool, name='mode_of_operation')\n",
        "    input_layer = tf.placeholder(dtype=tf.float32, shape=(batch_size, 9), name='input_images')\n",
        "    input_layer1 = tf.reshape(input_layer, [batch_size, 9, 1])\n",
        "    labels = tf.placeholder(dtype=tf.float32, shape=(batch_size, 1), name='gt_labels')\n",
        "    global_step = tf.Variable(0.0, trainable=False)\n",
        "\n",
        "    # 1st convolution layer\n",
        "    he_init_conv1 = tf.truncated_normal_initializer(mean=mean_conv1, stddev=sd_conv1)\n",
        "\n",
        "    conv1 = tf.layers.conv1d(inputs=input_layer1,\n",
        "                             kernel_size=3,\n",
        "                             filters=64,\n",
        "                             strides=1,\n",
        "                             padding='same',\n",
        "                             use_bias=True,\n",
        "                             activation=None,\n",
        "                             kernel_initializer=he_init_conv1,\n",
        "                             name='conv1')\n",
        "\n",
        "    '''m_1, v_1 = tf.nn.moments(x=conv1, axes=[0], keep_dims=False)\n",
        "    off_1 = tf.Variable(tf.zeros_like(m_1), name='off_1')\n",
        "    scale_1 = tf.Variable(tf.ones_like(m_1), name='scale_1')\n",
        "\n",
        "    bn_1 = tf.nn.batch_normalization(x=conv1, mean=m_1, variance=v_1, offset=off_1, scale=scale_1,\n",
        "                                     variance_epsilon=1e-1, name='bn1')'''\n",
        "\n",
        "    bn_1 = tf.layers.batch_normalization(inputs=conv1, momentum=0.9, axis=-1, training=mode, name='bn1')\n",
        "    conv1_bn = tf.nn.relu(bn_1, name='layer_1')\n",
        "\n",
        "    # 2nd convolutional layer\n",
        "    he_init_conv2 = tf.truncated_normal_initializer(mean=mean_conv2, stddev=sd_conv2)\n",
        "\n",
        "    conv2 = tf.layers.conv1d(inputs=conv1_bn,\n",
        "                             kernel_size=3,\n",
        "                             filters=64,\n",
        "                             strides=1,\n",
        "                             padding='same',\n",
        "                             use_bias=True,\n",
        "                             activation=None,\n",
        "                             kernel_initializer=he_init_conv2,\n",
        "                             name='conv2')\n",
        "\n",
        "    '''m_2, v_2 = tf.nn.moments(x=conv2, axes=[0], keep_dims=False)\n",
        "    off_2 = tf.Variable(tf.zeros_like(m_2))\n",
        "    scale_2 = tf.Variable(tf.ones_like(m_2))\n",
        "\n",
        "    bn_2 = tf.nn.batch_normalization(x=conv2, mean=m_2, variance=v_2, offset=off_2, scale=scale_2,\n",
        "                                     variance_epsilon=1e-5, name='bn2')'''\n",
        "\n",
        "    bn_2 = tf.layers.batch_normalization(inputs=conv2, momentum=0.9, axis=-1, training=mode, name='bn2')\n",
        "    conv2_bn = tf.nn.relu(bn_2, name='layer_2')\n",
        "\n",
        "    # 3rd convolutional layer\n",
        "    he_init_conv3 = tf.truncated_normal_initializer(mean=mean_conv3, stddev=sd_conv3)\n",
        "\n",
        "    conv3 = tf.layers.conv1d(inputs=conv2_bn,\n",
        "                             kernel_size=3,\n",
        "                             filters=64,\n",
        "                             strides=1,\n",
        "                             padding='same',\n",
        "                             use_bias=True,\n",
        "                             activation=None,\n",
        "                             kernel_initializer=he_init_conv3,\n",
        "                             name='conv3')\n",
        "\n",
        "    '''m_3, v_3 = tf.nn.moments(x=conv3, axes=[0], keep_dims=False)\n",
        "    off_3 = tf.Variable(tf.zeros_like(m_3))\n",
        "    scale_3 = tf.Variable(tf.ones_like(m_3))\n",
        "\n",
        "    bn_3 = tf.nn.batch_normalization(x=conv3, mean=m_3, variance=v_3, offset=off_3, scale=scale_3,\n",
        "                                     variance_epsilon=1e-5, name='bn3')'''\n",
        "\n",
        "    bn_3 = tf.layers.batch_normalization(inputs=conv3, momentum=0.9, axis=-1, training=mode, name='bn3')\n",
        "    conv3_bn = tf.nn.relu(bn_3, name='layer_3')\n",
        "\n",
        "    he_init_conv4 = tf.truncated_normal_initializer(mean=mean_conv4, stddev=sd_conv4)\n",
        "\n",
        "    conv4 = tf.layers.conv1d(inputs=conv3_bn,\n",
        "                             kernel_size=3,\n",
        "                             filters=64,\n",
        "                             strides=1,\n",
        "                             padding='same',\n",
        "                             use_bias=True,\n",
        "                             activation=None,\n",
        "                             kernel_initializer=he_init_conv4,\n",
        "                             name='conv4')\n",
        "\n",
        "    bn_4 = tf.layers.batch_normalization(inputs=conv4, momentum=0.9, axis=-1, training=mode, name='bn4')\n",
        "    conv4_bn = tf.nn.relu(bn_4, name='layer_4')\n",
        "\n",
        "    shape = tf.shape(conv4_bn)\n",
        "    conv4_re = tf.reshape(conv4_bn, [batch_size, shape[1]*shape[2]])\n",
        "\n",
        "    dense1 = tf.layers.dense(inputs=conv4_re, units=196)\n",
        "    bn_5 = tf.layers.batch_normalization(inputs=dense1, momentum=0.9, axis=-1, training=mode, name='bn5')\n",
        "    dense1_act = tf.nn.relu(bn_5, name='dense_1')\n",
        "\n",
        "    dropout = tf.layers.dropout(inputs=dense1_act, rate=0.2, training=mode)\n",
        "    predict = tf.layers.dense(inputs=dropout, units=1, name='predict')\n",
        "\n",
        "    loss = tf.losses.mean_squared_error(labels, predict)\n",
        "\n",
        "    lr = tf.train.exponential_decay(9e-4, global_step, 15000, 1.5, staircase=True)\n",
        "    optimizer = tf.train.MomentumOptimizer(learning_rate=lr, momentum=0.9)\n",
        "\n",
        "    update_ops = tf.get_collection(tf.GraphKeys.UPDATE_OPS)\n",
        "    with tf.control_dependencies(update_ops):\n",
        "        train_op = optimizer.minimize(loss=loss,\n",
        "                                      global_step=global_step)\n",
        "\n",
        "    predictions = tf.add(predict, tf.zeros_like(predict), name='prediction')\n",
        "\n",
        "saver = tf.train.Saver()\n",
        "config = tf.ConfigProto()\n",
        "config.gpu_options.allocator_type = 'BFC'\n",
        "\n",
        "\n",
        "with tf.Session(config=config) as sess:\n",
        "    # Load training and eval data\n",
        "    train_dir_path = 'train'\n",
        "    train_data, train_label = fetch_1d_data(train_dir_path)\n",
        "\n",
        "    train_data = np.array(train_data, dtype=np.float32)\n",
        "    train_label = np.array(train_label, dtype=np.int32)\n",
        "\n",
        "    sess.run(tf.global_variables_initializer())\n",
        "    sess.run(tf.local_variables_initializer())\n",
        "\n",
        "    for i in range(epochs):\n",
        "        index = np.arange(0, train_data.shape[0] - batch_size)\n",
        "        shuffle(index)\n",
        "        for t in range(0, len(index) - batch_size, batch_size):\n",
        "            data = {input_layer: train_data[index[t:t + batch_size]],\n",
        "                    labels: train_label[index[t:t + batch_size]],\n",
        "     "
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}